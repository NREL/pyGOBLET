{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3536f5f6",
   "metadata": {},
   "source": [
    "<h1><center> Tutorial 1: Configuring Algorithms for Testing </center></h1>\n",
    "\n",
    "---\n",
    "\n",
    "This tutorial teaches you how to implement optimization algorithms for benchmarking with pyGOLD. You'll learn the `BaseOptimizer` interface and see examples implementing multiple types of algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea2267d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pygold.optimizer import BaseOptimizer, OptimizationResult\n",
    "import pygold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67504ec3",
   "metadata": {},
   "source": [
    "## Part 1: The BaseOptimizer Interface\n",
    "---\n",
    "\n",
    "All algorithms in pyGOLD must inherit from `BaseOptimizer` and implement:\n",
    "\n",
    "1. `deterministic` (bool): Whether the algorithm produces the same result given the same inputs\n",
    "2. `n_points` (int): How many initial points the algorithm needs\n",
    "3. `optimize()` method: The main optimization function\n",
    "\n",
    "The attribute `n_points` defines how many initial points the benchmark runner will provide to the algorithm.\n",
    "\n",
    "- `n_points = 0`: Algorithm doesn't need initial points (e.g., a deterministic region exploration algorithm)\n",
    "- `n_points = 1`: Algorithm needs a single starting point (e.g., a basin-hopping algorithm)\n",
    "- `n_points > 1`: Algorithm needs multiple initial points (e.g., a population-based algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a008290",
   "metadata": {},
   "source": [
    "## Part 2: SciPy Examples\n",
    "---\n",
    "\n",
    "Let's start with wrapping some scipy algorithms. In addition to the `deterministic` and `n_points` attributes, each algorithm implements the optimize method with the signature: \n",
    "\n",
    "> optimize(self, func, bounds, x0=None, constraints=None, **kwargs)\n",
    "\n",
    "Your algorithm may not require an initial point or support constraints. The optimize method is still expected to accept them as arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07012010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution, basinhopping, dual_annealing, shgo\n",
    "\n",
    "# Dual Annealing: stochastic, no initial conditions\n",
    "class DualAnnealing(BaseOptimizer):\n",
    "    deterministic = False\n",
    "    n_points = 0\n",
    "\n",
    "    def optimize(self, func, bounds, x0=None, constraints=None, **kwargs):\n",
    "        result = dual_annealing(func, bounds, **kwargs)\n",
    "        return OptimizationResult(result.x, result.fun, algorithm=self.name)\n",
    "\n",
    "# Basin Hopping: stochastic, single initial condition\n",
    "class BasinHopping(BaseOptimizer):\n",
    "    deterministic = False\n",
    "    n_points = 1\n",
    "\n",
    "    def optimize(self, func, bounds, x0=None, constraints=None, **kwargs):\n",
    "        minimizer_kwargs = {'bounds': bounds}\n",
    "        result = basinhopping(func, x0, minimizer_kwargs=minimizer_kwargs, **kwargs)\n",
    "        return OptimizationResult(result.x, result.fun, algorithm=self.name)\n",
    "\n",
    "# Differential Evolution: stochastic, multiple initial conditions\n",
    "class DifferentialEvolution(BaseOptimizer):\n",
    "    deterministic = False\n",
    "    n_points = 15\n",
    "\n",
    "    def optimize(self, func, bounds, x0=None, constraints=None, **kwargs):\n",
    "        result = differential_evolution(func, bounds, init=x0, **kwargs)\n",
    "        return OptimizationResult(result.x, result.fun, algorithm=self.name)\n",
    "\n",
    "# SHGO: deterministic, no initial conditions\n",
    "class SHGO(BaseOptimizer):\n",
    "    deterministic = True\n",
    "    n_points = 0\n",
    "\n",
    "    def optimize(self, func, bounds, x0=None, constraints=None, **kwargs):\n",
    "        # Configure parameters\n",
    "        shgo_kwargs = {\n",
    "            'n': 100,\n",
    "            'iters': 5,\n",
    "            'sampling_method': 'sobol',\n",
    "            'minimizer_kwargs': {'method': 'L-BFGS-B', 'options': {'ftol': 1e-8}}\n",
    "        }\n",
    "\n",
    "        result = shgo(func, bounds, **shgo_kwargs)\n",
    "        return OptimizationResult(result.x, result.fun, algorithm=self.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca8aa2",
   "metadata": {},
   "source": [
    "## Part 3: A More Complex Example, The Pymoo Genetic Algorithm\n",
    "---\n",
    "\n",
    "Now let's implement a more sophisticated algorithm wrapper using the pymoo library. This is more complicated than the previous examples because the pymoo library requires problems to be defined as subclasses of the Problem class within the pymoo library. We must therefore create the problem and configure the algorithm within the optimize method. Apart from this, the approach is identical to the previous examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec701cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "class GeneticAlgorithm(BaseOptimizer):\n",
    "    deterministic = False  # GA is stochastic\n",
    "    n_points = 0           # Generates its own population\n",
    "\n",
    "    def optimize(self, func, bounds, x0=None, constraints=None, **kwargs):\n",
    "\n",
    "        # pymoo requires a problem defined as a subclass of Problem\n",
    "        class PymooProblem(ElementwiseProblem):\n",
    "            def __init__(self, objective_func, bounds):\n",
    "                n_var = len(bounds)\n",
    "                xl = np.array([b[0] for b in bounds])\n",
    "                xu = np.array([b[1] for b in bounds])\n",
    "                super().__init__(n_var=n_var, n_obj=1, xl=xl, xu=xu)\n",
    "                self.objective_func = objective_func\n",
    "                self.n_calls = 0\n",
    "\n",
    "            def _evaluate(self, x, out, *args, **kwargs):\n",
    "                self.n_calls += 1\n",
    "                out[\"F\"] = self.objective_func(x)\n",
    "\n",
    "        # Create the problem\n",
    "        problem = PymooProblem(func, bounds)\n",
    "\n",
    "        # Configure the algorithm\n",
    "        algorithm = GA(pop_size=100, eliminate_duplicates=True)\n",
    "\n",
    "        # Run optimization\n",
    "        res = minimize(problem, algorithm, ('n_gen', 100), verbose=False)\n",
    "\n",
    "        return OptimizationResult(x=res.X, fun=res.F[0], algorithm=self.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd63c34",
   "metadata": {},
   "source": [
    "## Part 4: Validate Implementations\n",
    "---\n",
    "\n",
    "Let's validate our algorithm implementations by running them on a test problem and displaying the number of function evaluations used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b1611a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 11:48:25] Multiple instances of codecarbon are allowed to run at the same time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with problem: Schaffer4\n",
      "Running DualAnnealing on Schaffer4 in 2D, iteration 1/2\n",
      "Running DualAnnealing on Schaffer4 in 2D, iteration 2/2\n",
      "Running BasinHopping on Schaffer4 in 2D, iteration 1/2\n",
      "Running BasinHopping on Schaffer4 in 2D, iteration 2/2\n",
      "Running DifferentialEvolution on Schaffer4 in 2D, iteration 1/2\n",
      "Running DifferentialEvolution on Schaffer4 in 2D, iteration 2/2\n",
      "Running SHGO on Schaffer4 in 2D, iteration 1/1\n",
      "Running GeneticAlgorithm on Schaffer4 in 2D, iteration 1/2\n",
      "Running GeneticAlgorithm on Schaffer4 in 2D, iteration 2/2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>solver</th>\n",
       "      <th>n_dims</th>\n",
       "      <th>target_0.1</th>\n",
       "      <th>target_0.01</th>\n",
       "      <th>target_0.0001</th>\n",
       "      <th>target_1e-08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schaffer4</td>\n",
       "      <td>BasinHopping</td>\n",
       "      <td>2</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>3316.0</td>\n",
       "      <td>3484.0</td>\n",
       "      <td>3910.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schaffer4</td>\n",
       "      <td>DifferentialEvolution</td>\n",
       "      <td>2</td>\n",
       "      <td>53.5</td>\n",
       "      <td>229.5</td>\n",
       "      <td>913.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schaffer4</td>\n",
       "      <td>DualAnnealing</td>\n",
       "      <td>2</td>\n",
       "      <td>186.5</td>\n",
       "      <td>897.5</td>\n",
       "      <td>1118.5</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schaffer4</td>\n",
       "      <td>GeneticAlgorithm</td>\n",
       "      <td>2</td>\n",
       "      <td>287.5</td>\n",
       "      <td>997.5</td>\n",
       "      <td>3278.0</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schaffer4</td>\n",
       "      <td>SHGO</td>\n",
       "      <td>2</td>\n",
       "      <td>662.0</td>\n",
       "      <td>6675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     problem                 solver  n_dims  target_0.1  target_0.01  \\\n",
       "0  Schaffer4           BasinHopping       2      1822.0       3316.0   \n",
       "1  Schaffer4  DifferentialEvolution       2        53.5        229.5   \n",
       "2  Schaffer4          DualAnnealing       2       186.5        897.5   \n",
       "3  Schaffer4       GeneticAlgorithm       2       287.5        997.5   \n",
       "4  Schaffer4                   SHGO       2       662.0       6675.0   \n",
       "\n",
       "   target_0.0001  target_1e-08  \n",
       "0         3484.0        3910.0  \n",
       "1          913.0           NaN  \n",
       "2         1118.5        2013.0  \n",
       "3         3278.0        6302.0  \n",
       "4            NaN           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a simple test problem\n",
    "problems = pygold.get_standard_problems([\"2D\", \"Unconstrained\"])\n",
    "test_problem = problems[3]  # Just use one\n",
    "\n",
    "print(f\"Testing with problem: {test_problem.__name__}\")\n",
    "\n",
    "# Create instances of our algorithms\n",
    "solvers = [\n",
    "    DualAnnealing(),\n",
    "    BasinHopping(),\n",
    "    DifferentialEvolution(),\n",
    "    SHGO(),\n",
    "    GeneticAlgorithm()\n",
    "]\n",
    "\n",
    "# Quick test run\n",
    "pygold.run_solvers(solvers=solvers, problems=[test_problem], test_dimensions=[2], n_iters=2, output_folder=\"algorithm_test\", verbose=True)\n",
    "\n",
    "# Postprocess performance data\n",
    "res = pygold.postprocess_data([\"algorithm_test/BasinHopping\", \"algorithm_test/DifferentialEvolution\", \"algorithm_test/DualAnnealing\", \"algorithm_test/GeneticAlgorithm\", \"algorithm_test/SHGO\"])\n",
    "\n",
    "# Display results\n",
    "display(res['data']['mean_fevals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee9aba5",
   "metadata": {},
   "source": [
    "## Part 5: Additional Notes\n",
    "---\n",
    "### Handle Constraints\n",
    "\n",
    "If your solver supports constraints and you indend to test it with constrained problems, ensure you handle the constraints properly. The constraint functions will return negative values when violated. \n",
    "\n",
    "For example, to run SHGO with constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "716024fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShgoConstraints(BaseOptimizer):\n",
    "    deterministic = True\n",
    "    n_points = 0\n",
    "\n",
    "    def optimize(self, func, bounds, x0=None, constraints=None, **kwargs):\n",
    "        # Convert constraints to the format expected by shgo\n",
    "        cons = [{'type': 'ineq', 'fun': c} for c in constraints] if constraints else []\n",
    "\n",
    "        result = shgo(func, bounds, constraints=cons, **kwargs)\n",
    "        return OptimizationResult(result.x, result.fun, algorithm=self.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99db214",
   "metadata": {},
   "source": [
    "### Common Implementation Pattern\n",
    "\n",
    "Most algorithms will have an implementation similar to this:\n",
    "\n",
    "```python\n",
    "class MyAlgorithm(BaseOptimizer):\n",
    "    deterministic = (bool)\n",
    "    n_points = (int)\n",
    "    \n",
    "    def optimize(self, func, bounds, x0=None, constraints=None, **kwargs):\n",
    "        # Call your algorithm\n",
    "        result = my_algorithm(func, bounds, x0)\n",
    "        return OptimizationResult(result.x, result.fun, algorithm=self.name)\n",
    "```\n",
    "\n",
    "## Summary\n",
    "---\n",
    "\n",
    "You now know how to:\n",
    "- Implement algorithms from the `BaseOptimizer` interface\n",
    "- Handle different initial condition requirements\n",
    "- Distinguish deterministic vs stochastic algorithms\n",
    "- Handle constraints properly\n",
    "\n",
    "Next: **Tutorial 2** will show you how to run complete experiments with your algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyGOLD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
